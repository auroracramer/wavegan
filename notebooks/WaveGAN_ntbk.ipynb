{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import os\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import pescador\n",
    "import librosa\n",
    "import pprint\n",
    "from IPython.display import Audio\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
    "    by a random integer in {-n, n} and performing reflection padding where\n",
    "    necessary\n",
    "\n",
    "    If batch shuffle is enabled, only a single shuffle is applied to the entire\n",
    "    batch, rather than each sample in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shift_factor, batch_shuffle=False):\n",
    "        super(PhaseShuffle, self).__init__()\n",
    "        self.shift_factor = shift_factor\n",
    "        self.batch_shuffle = batch_shuffle\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Return x if phase shift is disabled\n",
    "        if self.shift_factor == 0:\n",
    "            return x\n",
    "\n",
    "        if self.batch_shuffle:\n",
    "            # Make sure to use PyTorcTrueh to generate number RNG state is all shared\n",
    "            k = int(torch.Tensor(1).random_(0, 2*self.shift_factor + 1)) - self.shift_factor\n",
    "\n",
    "            # Return if no phase shift\n",
    "            if k == 0:\n",
    "                return x\n",
    "\n",
    "            # Slice feature dimension\n",
    "            if k > 0:\n",
    "                x_trunc = x[:, :, :-k]\n",
    "                pad = (k, 0)\n",
    "            else:\n",
    "                x_trunc = x[:, :, -k:]\n",
    "                pad = (0, -k)\n",
    "\n",
    "            # Reflection padding\n",
    "            x_shuffle = F.pad(x_trunc, pad, mode='reflect')\n",
    "\n",
    "        else:\n",
    "            # Generate shifts for each sample in the batch\n",
    "            k_list = torch.Tensor(x.shape[0]).random_(0, 2*self.shift_factor+1)\\\n",
    "                - self.shift_factor\n",
    "            k_list = k_list.numpy().astype(int)\n",
    "\n",
    "            # Combine sample indices into lists so that less shuffle operations\n",
    "            # need to be performed\n",
    "            k_map = {}\n",
    "            for idx, k in enumerate(k_list):\n",
    "                k = int(k)\n",
    "                if k not in k_map:\n",
    "                    k_map[k] = []\n",
    "                k_map[k].append(idx)\n",
    "\n",
    "            # Make a copy of x for our output\n",
    "            x_shuffle = x.clone()\n",
    "\n",
    "            # Apply shuffle to each sample\n",
    "            for k, idxs in k_map.items():\n",
    "                if k > 0:\n",
    "                    x_shuffle[idxs] = F.pad(x[idxs][..., :-k], (k,0), mode='reflect')\n",
    "                else:\n",
    "                    x_shuffle[idxs] = F.pad(x[idxs][..., -k:], (0,-k), mode='reflect')\n",
    "\n",
    "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape,\n",
    "                                                           x.shape)\n",
    "        return x_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        if upsample:\n",
    "            self.upsample_layer = torch.nn.Upsample(scale_factor=upsample)\n",
    "            reflection_padding = kernel_size // 2\n",
    "            self.reflection_pad = ConstantPad1d(reflection_padding)\n",
    "#             self.reflection_pad = torch.nn.ReflectionPad1d(reflection_padding)\n",
    "            self.conv1d = torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = self.upsample_layer(x_in)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv1d(out)\n",
    "        return out\n",
    "\n",
    "class WaveGANGenerator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, latent_dim=100,\n",
    "                 post_proc_filt_len=512, verbose=False, upsample=True):\n",
    "        super(WaveGANGenerator, self).__init__()\n",
    "        self.ngpus = ngpus\n",
    "        self.model_size = model_size # d\n",
    "        self.num_channels = num_channels # c\n",
    "        self.latent_dim = latent_dim\n",
    "        self.post_proc_filt_len = post_proc_filt_len\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(latent_dim, 256 * model_size))\n",
    "        \n",
    "        self.tconv1 = None\n",
    "        self.tconv2 = None\n",
    "        self.tconv3 = None\n",
    "        self.tconv4 = None\n",
    "        self.tconv5 = None\n",
    "        \n",
    "                \n",
    "        self.upSampConv1 = None\n",
    "        self.upSampConv2 = None\n",
    "        self.upSampConv3 = None\n",
    "        self.upSampConv4 = None\n",
    "        self.upSampConv5 = None\n",
    "        \n",
    "        self.upsample = upsample\n",
    "    \n",
    "        if self.upsample:\n",
    "            self.upSampConv1 = nn.DataParallel(\n",
    "                UpsampleConvLayer(16 * model_size, 8 * model_size, 25, stride=1, upsample=4))\n",
    "            self.upSampConv2 = nn.DataParallel(\n",
    "                UpsampleConvLayer(8 * model_size, 4 * model_size, 25, stride=1, upsample=4))\n",
    "            self.upSampConv3 = nn.DataParallel(\n",
    "                UpsampleConvLayer(4 * model_size, 2 * model_size, 25, stride=1, upsample=4))\n",
    "            self.upSampConv4 = nn.DataParallel(\n",
    "                UpsampleConvLayer(2 * model_size, model_size, 25, stride=1, upsample=4))\n",
    "            self.upSampConv5 = nn.DataParallel(\n",
    "                UpsampleConvLayer(model_size, num_channels, 25, stride=1, upsample=4))\n",
    "            \n",
    "        else:\n",
    "            self.tconv1 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(16 * model_size, 8 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv2 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(8 * model_size, 4 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv3 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(4 * model_size, 2 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv4 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(2 * model_size, model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv5 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(model_size, num_channels, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "\n",
    "        if post_proc_filt_len:\n",
    "            self.ppfilter1 = nn.DataParallel(nn.Conv1d(num_channels, num_channels, post_proc_filt_len))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x).view(-1, 16 * self.model_size, 16)\n",
    "        x = F.relu(x)\n",
    "        output = None\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        \n",
    "        if self.upsample:\n",
    "            x = F.relu(self.upSampConv1(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv2(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv3(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv4(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            output = F.tanh(self.upSampConv5(x))\n",
    "        else:\n",
    "            x = F.relu(self.tconv1(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv2(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv3(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv4(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            output = F.tanh(self.tconv5(x))\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(output.shape)\n",
    "\n",
    "        if self.post_proc_filt_len:\n",
    "            # Pad for \"same\" filtering\n",
    "            if (self.post_proc_filt_len % 2) == 0:\n",
    "                pad_left = self.post_proc_filt_len // 2\n",
    "                pad_right = pad_left - 1\n",
    "            else:\n",
    "                pad_left = (self.post_proc_filt_len - 1) // 2\n",
    "                pad_right = pad_left\n",
    "            output = self.ppfilter1(F.pad(output, (pad_left, pad_right)))\n",
    "            if self.verbose:\n",
    "                print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class WaveGANDiscriminator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2, alpha=0.2, batch_shuffle=False, verbose=False):\n",
    "        super(WaveGANDiscriminator, self).__init__()\n",
    "        self.model_size = model_size # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels # c\n",
    "        self.shift_factor = shift_factor # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, etc.)\n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "        self.ps1 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps2 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps3 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps4 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, 1))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        x = self.ps2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps4(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        return F.sigmoid(self.fc1(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavegan_generator(filepath, model_size=64, ngpus=1, num_channels=1,\n",
    "                           latent_dim=100, post_proc_filt_len=512, **kwargs):\n",
    "    model = WaveGANGenerator(model_size=model_size, ngpus=ngpus,\n",
    "                             num_channels=num_channels, latent_dim=latent_dim,\n",
    "                             post_proc_filt_len=post_proc_filt_len)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_wavegan_discriminator(filepath, model_size=64, ngpus=1, num_channels=1,\n",
    "                               shift_factor=2, alpha=0.2, **kwargs):\n",
    "    model = WaveGANDiscriminator(model_size=model_size, ngpus=ngpus,\n",
    "                                 num_channels=num_channels,\n",
    "                                 shift_factor=shift_factor, alpha=alpha)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discr_loss_terms(model_dis, model_gen, real_data_v, noise_v,\n",
    "                             batch_size, latent_dim,\n",
    "                             lmbda, use_cuda, compute_grads=False):\n",
    "    # Convenient values for\n",
    "    one = torch.FloatTensor([1])\n",
    "    neg_one = one * -1\n",
    "    if use_cuda:\n",
    "        one = one.cuda()\n",
    "        neg_one = neg_one.cuda()\n",
    "\n",
    "    # Reset gradients\n",
    "    model_dis.zero_grad()\n",
    "\n",
    "    # a) Compute loss contribution from real training data and backprop\n",
    "    # (negative of the empirical mean, w.r.t. the data distribution, of the discr. output)\n",
    "    D_real = model_dis(real_data_v)\n",
    "    D_real = D_real.mean()\n",
    "    # Negate since we want to _maximize_ this quantity\n",
    "    if compute_grads:\n",
    "        D_real.backward(neg_one)\n",
    "\n",
    "    # b) Compute loss contribution from generated data and backprop\n",
    "    # (empirical mean, w.r.t. the generator distribution, of the discr. output)\n",
    "    # Generate noise in latent space\n",
    "\n",
    "    # Generate data by passing noise through the generator\n",
    "    fake = autograd.Variable(model_gen(noise_v).data)\n",
    "    inputv = fake\n",
    "#     print(fake)\n",
    "    D_fake = model_dis(inputv)\n",
    "    D_fake = D_fake.mean()\n",
    "    if compute_grads:\n",
    "        D_fake.backward(one)\n",
    "\n",
    "    # c) Compute gradient penalty and backprop\n",
    "    gradient_penalty = calc_gradient_penalty(model_dis, real_data_v.data,\n",
    "                                             fake.data,\n",
    "                                             batch_size, lmbda,\n",
    "                                             use_cuda=use_cuda)\n",
    "\n",
    "    if compute_grads:\n",
    "        gradient_penalty.backward(one)\n",
    "\n",
    "    # Compute metrics and record in batch history\n",
    "    D_cost = D_fake - D_real + gradient_penalty\n",
    "    Wasserstein_D = D_real - D_fake\n",
    "\n",
    "    return D_cost, Wasserstein_D\n",
    "\n",
    "\n",
    "def compute_gener_loss_terms(model_dis, model_gen, batch_size, latent_dim,\n",
    "                             use_cuda, compute_grads=False):\n",
    "    # Convenient values for\n",
    "    one = torch.FloatTensor([1])\n",
    "    neg_one = one * -1\n",
    "    if use_cuda:\n",
    "        one = one.cuda()\n",
    "        neg_one = neg_one.cuda()\n",
    "\n",
    "    # Reset generator gradients\n",
    "    model_gen.zero_grad()\n",
    "\n",
    "    # Sample from the generator\n",
    "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda()\n",
    "    noise_v = autograd.Variable(noise)\n",
    "    fake = model_gen(noise_v)\n",
    "\n",
    "    # Compute generator loss and backprop\n",
    "    # (negative of empirical mean (w.r.t generator distribution) of discriminator output)\n",
    "    G = model_dis(fake)\n",
    "    G = G.mean()\n",
    "    if compute_grads:\n",
    "        G.backward(neg_one)\n",
    "    G_cost = -G\n",
    "\n",
    "    return G_cost\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sample_generator(filepath, window_length=16384, fs=16000):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(filepath, sr=fs)\n",
    "\n",
    "        # Clip amplitude\n",
    "        max_amp = np.max(np.abs(audio_data))\n",
    "        if max_amp > 1:\n",
    "            audio_data /= max_amp\n",
    "    except Exception as e:\n",
    "        print('Could not load {}: {}'.format(filepath, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    audio_len = len(audio_data)\n",
    "\n",
    "    # Pad audio to at least a single frame\n",
    "    if audio_len < window_length:\n",
    "        pad_length = window_length - audio_len\n",
    "        left_pad = pad_length // 2\n",
    "        right_pad = pad_length - left_pad\n",
    "\n",
    "        audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
    "        audio_len = len(audio_data)\n",
    "\n",
    "    while True:\n",
    "        if audio_len == window_length:\n",
    "            # If we only have a single frame's worth of audio, just yield the whole audio\n",
    "            sample = audio_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, audio_len - window_length)\n",
    "            end_idx = start_idx + window_length\n",
    "            sample = audio_data[start_idx:end_idx]\n",
    "\n",
    "        sample = sample.astype('float32')\n",
    "        assert not np.any(np.isnan(sample))\n",
    "\n",
    "        yield {'X': sample}\n",
    "\n",
    "\n",
    "def create_batch_generator(audio_filepath_list, batch_size):\n",
    "    streamers = []\n",
    "    for audio_filepath in audio_filepath_list:\n",
    "        s = pescador.Streamer(file_sample_generator, audio_filepath)\n",
    "        streamers.append(s)\n",
    "\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir, followlinks=True)\n",
    "            for fname in file_names\n",
    "            if (fname.lower().endswith('.wav') or fname.lower().endswith('.mp3'))]\n",
    "\n",
    "\n",
    "def create_data_split(audio_filepath_list, valid_ratio, test_ratio,\n",
    "                      train_batch_size, valid_size, test_size):\n",
    "    num_files = len(audio_filepath_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "\n",
    "    assert num_valid > 0\n",
    "    assert num_test > 0\n",
    "    assert num_train > 0\n",
    "\n",
    "    valid_files = audio_filepath_list[:num_valid]\n",
    "    test_files = audio_filepath_list[num_valid:num_valid + num_test]\n",
    "    train_files = audio_filepath_list[num_valid + num_test:]\n",
    "\n",
    "    train_gen = create_batch_generator(train_files, train_batch_size)\n",
    "    valid_data = next(iter(create_batch_generator(valid_files, valid_size)))\n",
    "    test_data = next(iter(create_batch_generator(test_files, test_size)))\n",
    "\n",
    "    return train_gen, valid_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(epoch_samples, epoch, output_dir, fs=16000):\n",
    "    \"\"\"\n",
    "    Save output samples to disk\n",
    "    \"\"\"\n",
    "    sample_dir = os.path.join(output_dir, str(epoch))\n",
    "    if not os.path.exists(sample_dir):\n",
    "        os.makedirs(sample_dir)\n",
    "\n",
    "    for idx, samp in enumerate(epoch_samples):\n",
    "        output_path = os.path.join(sample_dir, \"{}.wav\".format(idx+1))\n",
    "        samp = samp[0]\n",
    "        librosa.output.write_wav(output_path, samp, fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_input_var(data, use_cuda):\n",
    "    data = data[:,np.newaxis,:]\n",
    "    data = torch.Tensor(data)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    return autograd.Variable(data)\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def calc_gradient_penalty(model_dis, real_data, fake_data, batch_size, lmbda, use_cuda=True):\n",
    "    # Compute interpolation factors\n",
    "    alpha = torch.rand(batch_size, 1, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda() if use_cuda else alpha\n",
    "\n",
    "    # Interpolate between real and fake data\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    # Evaluate discriminator\n",
    "    disc_interpolates = model_dis(interpolates)\n",
    "\n",
    "    # Obtain gradients of the discriminator with respect to the inputs\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else torch.ones(\n",
    "                                  disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    # Compute MSE between 1.0 and the gradient of the norm penalty to encourage discriminator\n",
    "    # to be a 1-Lipschitz function\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lmbda\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def train_wgan(model_gen, model_dis, train_gen, valid_data, test_data,\n",
    "               num_epochs, batches_per_epoch, batch_size, output_dir=None,\n",
    "               lmbda=0.1, use_cuda=True, discriminator_updates=5, epochs_per_sample=10,\n",
    "               sample_size=20, lr=1e-4, beta_1=0.5, beta_2=0.9, latent_dim=100):\n",
    "\n",
    "    if use_cuda:\n",
    "        model_gen = model_gen.cuda()\n",
    "        model_dis = model_dis.cuda()\n",
    "\n",
    "    # Initialize optimizers for each model\n",
    "    optimizer_gen = optim.Adam(model_gen.parameters(), lr=lr,\n",
    "                               betas=(beta_1, beta_2))\n",
    "    optimizer_dis = optim.Adam(model_dis.parameters(), lr=lr,\n",
    "                               betas=(beta_1, beta_2))\n",
    "\n",
    "    # Sample noise used for seeing the evolution of generated output samples throughout training\n",
    "    sample_noise = torch.Tensor(sample_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        sample_noise = sample_noise.cuda()\n",
    "    sample_noise_v = autograd.Variable(sample_noise)\n",
    "\n",
    "    samples = {}\n",
    "    history = []\n",
    "\n",
    "    train_iter = iter(train_gen)\n",
    "    valid_data_v = np_to_input_var(valid_data['X'], use_cuda)\n",
    "    test_data_v = np_to_input_var(test_data['X'], use_cuda)\n",
    "\n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch+1)) \n",
    "\n",
    "        epoch_history = []\n",
    "\n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "\n",
    "            # Set model parameters to require gradients to be computed and stored\n",
    "            for p in model_dis.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            # Initialize the metrics for this batch\n",
    "            batch_history = {\n",
    "                'discriminator': [],\n",
    "                'generator': {}\n",
    "            }\n",
    "\n",
    "            # Discriminator Training Phase:\n",
    "            # -> Train discriminator k times\n",
    "            for iter_d in range(discriminator_updates):\n",
    "                # Get real examples\n",
    "                real_data_v = np_to_input_var(next(train_iter)['X'], use_cuda)\n",
    "\n",
    "                # Get noise\n",
    "                noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "                if use_cuda:\n",
    "                    noise = noise.cuda()\n",
    "                noise_v = autograd.Variable(noise,\n",
    "                                            volatile=True)  # totally freeze model_gen\n",
    "\n",
    "                # Get new batch of real training data\n",
    "                D_cost_train, D_wass_train = compute_discr_loss_terms(\n",
    "                    model_dis, model_gen, real_data_v, noise_v, batch_size,\n",
    "                    latent_dim,\n",
    "                    lmbda, use_cuda, compute_grads=True)\n",
    "\n",
    "                # Update the discriminator\n",
    "                optimizer_dis.step()\n",
    "\n",
    "                D_cost_valid, D_wass_valid = compute_discr_loss_terms(\n",
    "                    model_dis, model_gen, valid_data_v, noise_v, batch_size,\n",
    "                    latent_dim,\n",
    "                    lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "                if use_cuda:\n",
    "                    D_cost_train = D_cost_train.cpu()\n",
    "                    D_cost_valid = D_cost_valid.cpu()\n",
    "                    D_wass_train = D_wass_train.cpu()\n",
    "                    D_wass_valid = D_wass_valid.cpu()\n",
    "\n",
    "                batch_history['discriminator'].append({\n",
    "                    'cost': D_cost_train.data.numpy()[0],\n",
    "                    'wasserstein_cost': D_wass_train.data.numpy()[0],\n",
    "                    'cost_validation': D_cost_valid.data.numpy()[0],\n",
    "                    'wasserstein_cost_validation': D_wass_valid.data.numpy()[0]\n",
    "                })\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "            # Prevent discriminator from computing gradients, since\n",
    "            # we are only updating the generator\n",
    "            for p in model_dis.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            G_cost = compute_gener_loss_terms(model_dis, model_gen, batch_size,\n",
    "                                              latent_dim,\n",
    "                                              use_cuda, compute_grads=True)\n",
    "\n",
    "            # Update generator\n",
    "            optimizer_gen.step()\n",
    "\n",
    "            if use_cuda:\n",
    "                G_cost = G_cost.cpu()\n",
    "\n",
    "            # Record generator loss\n",
    "            batch_history['generator']['cost'] = G_cost.data.numpy()[0]\n",
    "\n",
    "            # Record batch metrics\n",
    "            epoch_history.append(batch_history)\n",
    "\n",
    "        # Record epoch metrics\n",
    "        history.append(epoch_history)\n",
    "\n",
    "        print(pprint.pformat(epoch_history[-1]))\n",
    "\n",
    "        if (epoch + 1) % epochs_per_sample == 0:\n",
    "            # Generate outputs for fixed latent samples\n",
    "            print('Generating samples...')\n",
    "            samp_output = model_gen(sample_noise_v)\n",
    "            if use_cuda:\n",
    "                samp_output = samp_output.cpu()\n",
    "\n",
    "            samples[epoch+1] = samp_output.data.numpy()\n",
    "            if output_dir:\n",
    "                print('Saving samples...')\n",
    "                save_samples(samples[epoch+1], epoch+1, output_dir)\n",
    "\n",
    "    ## Get final discriminator loss\n",
    "    # Get noise\n",
    "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda()\n",
    "    noise_v = autograd.Variable(noise,\n",
    "                                volatile=True)  # totally freeze model_gen\n",
    "\n",
    "    # Get new batch of real training data\n",
    "    D_cost_test, D_wass_test = compute_discr_loss_terms(\n",
    "        model_dis, model_gen, test_data_v, noise_v, batch_size, latent_dim,\n",
    "        lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "    D_cost_valid, D_wass_valid = compute_discr_loss_terms(\n",
    "        model_dis, model_gen, valid_data_v, noise_v, batch_size, latent_dim,\n",
    "        lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "    if use_cuda:\n",
    "        D_cost_test = D_cost_test.cpu()\n",
    "        D_cost_valid = D_cost_valid.cpu()\n",
    "        D_wass_test = D_wass_test.cpu()\n",
    "        D_wass_valid = D_wass_valid.cpu()\n",
    "\n",
    "    final_discr_metrics = {\n",
    "        'cost_validation': D_cost_valid.data.numpy()[0],\n",
    "        'wasserstein_cost_validation': D_wass_valid.data.numpy()[0],\n",
    "        'cost_test': D_cost_test.data.numpy()[0],\n",
    "        'wasserstein_cost_test': D_wass_test.data.numpy()[0],\n",
    "    }\n",
    "\n",
    "    return model_gen, model_dis, history, final_discr_metrics, samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"../../wvgan_out\"\n",
    "model_dir = os.path.join(output_dir,\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    # Create output directory\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_size = 64\n",
    "phase_shuffle_shift_factor = 2 \n",
    "post_proc_filt_len = 512 \n",
    "lrelu_alpha = 0.2 \n",
    "valid_ratio = 0.1 \n",
    "test_ratio = 0.1 \n",
    "batch_size = 64 \n",
    "num_epochs = 100 \n",
    "batches_per_epoch = 10 \n",
    "ngpus = 1 \n",
    "discriminator_updates = 5 \n",
    "latent_dim = 100 \n",
    "epochs_per_sample = 1 \n",
    "sample_size = 20 \n",
    "learning_rate = 0.000001 \n",
    "beta_one = 0.5 \n",
    "beta_two = 0.9\n",
    "regularization_factor = 10.0 \n",
    "batch_shuffle = False\n",
    "\n",
    "audio_dir = \"/home/nl1115/gc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try on some training data\n",
    "print('Loading audio data...')\n",
    "audio_filepaths = get_all_audio_filepaths(audio_dir)\n",
    "train_gen, valid_data, test_data \\\n",
    "    = create_data_split(audio_filepaths, valid_ratio, test_ratio,\n",
    "                        batch_size, batch_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating models...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Creating models...')\n",
    "model_gen = WaveGANGenerator(model_size=model_size, ngpus=ngpus, latent_dim=latent_dim,\n",
    "                             post_proc_filt_len=post_proc_filt_len,upsample=True, verbose=False)\n",
    "model_dis = WaveGANDiscriminator(model_size=model_size, ngpus=ngpus,\n",
    "                                 alpha=lrelu_alpha, shift_factor=phase_shuffle_shift_factor,\n",
    "                                 batch_shuffle=batch_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveGANGenerator(\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (tconv1): DataParallel(\n",
      "    (module): ConvTranspose1d(1024, 512, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv2): DataParallel(\n",
      "    (module): ConvTranspose1d(512, 256, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv3): DataParallel(\n",
      "    (module): ConvTranspose1d(256, 128, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv4): DataParallel(\n",
      "    (module): ConvTranspose1d(128, 64, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv5): DataParallel(\n",
      "    (module): ConvTranspose1d(64, 1, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gen2 = WaveGANGenerator(model_size=model_size, ngpus=ngpus, latent_dim=latent_dim,\n",
    "                             post_proc_filt_len=post_proc_filt_len,upsample=False)\n",
    "print(model_gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveGANGenerator(\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (upSampConv1): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=bilinear)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(1024, 512, kernel_size=(25,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv2): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=bilinear)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(512, 256, kernel_size=(25,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv3): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=bilinear)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(256, 128, kernel_size=(25,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv4): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=bilinear)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(128, 64, kernel_size=(25,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv5): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=bilinear)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(64, 1, kernel_size=(25,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1\n",
      "{'discriminator': [{'cost': -0.10757208,\n",
      "                    'cost_validation': -0.11539169,\n",
      "                    'wasserstein_cost': 0.14743435,\n",
      "                    'wasserstein_cost_validation': 0.15518898},\n",
      "                   {'cost': -0.11302677,\n",
      "                    'cost_validation': -0.122496195,\n",
      "                    'wasserstein_cost': 0.15280634,\n",
      "                    'wasserstein_cost_validation': 0.16238439},\n",
      "                   {'cost': -0.11811,\n",
      "                    'cost_validation': -0.12560979,\n",
      "                    'wasserstein_cost': 0.15807638,\n",
      "                    'wasserstein_cost_validation': 0.16536844},\n",
      "                   {'cost': -0.1196219,\n",
      "                    'cost_validation': -0.121449314,\n",
      "                    'wasserstein_cost': 0.15958971,\n",
      "                    'wasserstein_cost_validation': 0.16150868},\n",
      "                   {'cost': -0.123776786,\n",
      "                    'cost_validation': -0.1295684,\n",
      "                    'wasserstein_cost': 0.16345769,\n",
      "                    'wasserstein_cost_validation': 0.16936514}],\n",
      " 'generator': {'cost': -0.3601242}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 2\n",
      "{'discriminator': [{'cost': -0.0236671,\n",
      "                    'cost_validation': -0.05368171,\n",
      "                    'wasserstein_cost': 0.05923301,\n",
      "                    'wasserstein_cost_validation': 0.08988568},\n",
      "                   {'cost': -0.023215309,\n",
      "                    'cost_validation': -0.051110175,\n",
      "                    'wasserstein_cost': 0.058767676,\n",
      "                    'wasserstein_cost_validation': 0.08727723},\n",
      "                   {'cost': -0.030965403,\n",
      "                    'cost_validation': -0.05803383,\n",
      "                    'wasserstein_cost': 0.06634584,\n",
      "                    'wasserstein_cost_validation': 0.09429014},\n",
      "                   {'cost': -0.03308628,\n",
      "                    'cost_validation': -0.06276187,\n",
      "                    'wasserstein_cost': 0.068291456,\n",
      "                    'wasserstein_cost_validation': 0.09888148},\n",
      "                   {'cost': -0.03070432,\n",
      "                    'cost_validation': -0.05073344,\n",
      "                    'wasserstein_cost': 0.06622529,\n",
      "                    'wasserstein_cost_validation': 0.08694211}],\n",
      " 'generator': {'cost': -0.45190582}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 3\n",
      "{'discriminator': [{'cost': 0.04545755,\n",
      "                    'cost_validation': 0.012093097,\n",
      "                    'wasserstein_cost': -0.0071185827,\n",
      "                    'wasserstein_cost_validation': 0.026827395},\n",
      "                   {'cost': 0.053060133,\n",
      "                    'cost_validation': 0.006810013,\n",
      "                    'wasserstein_cost': -0.014917374,\n",
      "                    'wasserstein_cost_validation': 0.0321458},\n",
      "                   {'cost': 0.043478712,\n",
      "                    'cost_validation': -0.00059841946,\n",
      "                    'wasserstein_cost': -0.005013764,\n",
      "                    'wasserstein_cost_validation': 0.039548457},\n",
      "                   {'cost': 0.049815007,\n",
      "                    'cost_validation': -0.0026359,\n",
      "                    'wasserstein_cost': -0.0114812255,\n",
      "                    'wasserstein_cost_validation': 0.041333973},\n",
      "                   {'cost': 0.02809706,\n",
      "                    'cost_validation': -0.0060938,\n",
      "                    'wasserstein_cost': 0.010412395,\n",
      "                    'wasserstein_cost_validation': 0.04486507}],\n",
      " 'generator': {'cost': -0.5437517}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 4\n",
      "{'discriminator': [{'cost': -0.12549776,\n",
      "                    'cost_validation': -0.17062026,\n",
      "                    'wasserstein_cost': 0.16458395,\n",
      "                    'wasserstein_cost_validation': 0.21055621},\n",
      "                   {'cost': -0.12524112,\n",
      "                    'cost_validation': -0.17242326,\n",
      "                    'wasserstein_cost': 0.16462183,\n",
      "                    'wasserstein_cost_validation': 0.21242774},\n",
      "                   {'cost': -0.14569214,\n",
      "                    'cost_validation': -0.18280077,\n",
      "                    'wasserstein_cost': 0.18536347,\n",
      "                    'wasserstein_cost_validation': 0.22312674},\n",
      "                   {'cost': -0.14121604,\n",
      "                    'cost_validation': -0.19036645,\n",
      "                    'wasserstein_cost': 0.18070337,\n",
      "                    'wasserstein_cost_validation': 0.22996816},\n",
      "                   {'cost': -0.1608876,\n",
      "                    'cost_validation': -0.1916204,\n",
      "                    'wasserstein_cost': 0.19985285,\n",
      "                    'wasserstein_cost_validation': 0.23138362}],\n",
      " 'generator': {'cost': -0.45188072}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 5\n",
      "{'discriminator': [{'cost': -0.20417976,\n",
      "                    'cost_validation': -0.2645635,\n",
      "                    'wasserstein_cost': 0.23965043,\n",
      "                    'wasserstein_cost_validation': 0.3017316},\n",
      "                   {'cost': -0.2090636,\n",
      "                    'cost_validation': -0.2734438,\n",
      "                    'wasserstein_cost': 0.24391499,\n",
      "                    'wasserstein_cost_validation': 0.30995682},\n",
      "                   {'cost': -0.23209141,\n",
      "                    'cost_validation': -0.27209243,\n",
      "                    'wasserstein_cost': 0.26736885,\n",
      "                    'wasserstein_cost_validation': 0.30879495},\n",
      "                   {'cost': -0.21977594,\n",
      "                    'cost_validation': -0.2786489,\n",
      "                    'wasserstein_cost': 0.25510323,\n",
      "                    'wasserstein_cost_validation': 0.3150104},\n",
      "                   {'cost': -0.23059745,\n",
      "                    'cost_validation': -0.28164348,\n",
      "                    'wasserstein_cost': 0.26629737,\n",
      "                    'wasserstein_cost_validation': 0.31782424}],\n",
      " 'generator': {'cost': -0.39772892}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 6\n",
      "{'discriminator': [{'cost': -0.05828694,\n",
      "                    'cost_validation': -0.16410278,\n",
      "                    'wasserstein_cost': 0.090381056,\n",
      "                    'wasserstein_cost_validation': 0.19614577},\n",
      "                   {'cost': -0.087505296,\n",
      "                    'cost_validation': -0.1726848,\n",
      "                    'wasserstein_cost': 0.12067586,\n",
      "                    'wasserstein_cost_validation': 0.20500484},\n",
      "                   {'cost': -0.042822536,\n",
      "                    'cost_validation': -0.17738545,\n",
      "                    'wasserstein_cost': 0.07518765,\n",
      "                    'wasserstein_cost_validation': 0.21015108},\n",
      "                   {'cost': -0.10759472,\n",
      "                    'cost_validation': -0.18232407,\n",
      "                    'wasserstein_cost': 0.14099059,\n",
      "                    'wasserstein_cost_validation': 0.21500537},\n",
      "                   {'cost': -0.074533045,\n",
      "                    'cost_validation': -0.18363674,\n",
      "                    'wasserstein_cost': 0.10771078,\n",
      "                    'wasserstein_cost_validation': 0.21659935}],\n",
      " 'generator': {'cost': -0.38224912}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 7\n",
      "{'discriminator': [{'cost': -0.197712,\n",
      "                    'cost_validation': -0.33255717,\n",
      "                    'wasserstein_cost': 0.23156169,\n",
      "                    'wasserstein_cost_validation': 0.36683935},\n",
      "                   {'cost': -0.2216553,\n",
      "                    'cost_validation': -0.33675414,\n",
      "                    'wasserstein_cost': 0.25480306,\n",
      "                    'wasserstein_cost_validation': 0.37036258},\n",
      "                   {'cost': -0.23736992,\n",
      "                    'cost_validation': -0.34380767,\n",
      "                    'wasserstein_cost': 0.27077386,\n",
      "                    'wasserstein_cost_validation': 0.377185},\n",
      "                   {'cost': -0.23312213,\n",
      "                    'cost_validation': -0.34633362,\n",
      "                    'wasserstein_cost': 0.26903397,\n",
      "                    'wasserstein_cost_validation': 0.38130865},\n",
      "                   {'cost': -0.23794268,\n",
      "                    'cost_validation': -0.3523179,\n",
      "                    'wasserstein_cost': 0.27073747,\n",
      "                    'wasserstein_cost_validation': 0.38600788}],\n",
      " 'generator': {'cost': -0.29104114}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 8\n",
      "{'discriminator': [{'cost': -0.45652738,\n",
      "                    'cost_validation': -0.5384175,\n",
      "                    'wasserstein_cost': 0.4902833,\n",
      "                    'wasserstein_cost_validation': 0.57370406},\n",
      "                   {'cost': -0.46212178,\n",
      "                    'cost_validation': -0.5446721,\n",
      "                    'wasserstein_cost': 0.49247918,\n",
      "                    'wasserstein_cost_validation': 0.57852066},\n",
      "                   {'cost': -0.45019382,\n",
      "                    'cost_validation': -0.5414529,\n",
      "                    'wasserstein_cost': 0.48209935,\n",
      "                    'wasserstein_cost_validation': 0.57994765},\n",
      "                   {'cost': -0.49255475,\n",
      "                    'cost_validation': -0.5557229,\n",
      "                    'wasserstein_cost': 0.528297,\n",
      "                    'wasserstein_cost_validation': 0.5895004},\n",
      "                   {'cost': -0.4851678,\n",
      "                    'cost_validation': -0.5616225,\n",
      "                    'wasserstein_cost': 0.51711166,\n",
      "                    'wasserstein_cost_validation': 0.5953343}],\n",
      " 'generator': {'cost': -0.22017802}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'discriminator': [{'cost': -0.16267757,\n",
      "                    'cost_validation': -0.2806571,\n",
      "                    'wasserstein_cost': 0.19260424,\n",
      "                    'wasserstein_cost_validation': 0.30841345},\n",
      "                   {'cost': -0.1379103,\n",
      "                    'cost_validation': -0.2856778,\n",
      "                    'wasserstein_cost': 0.16505682,\n",
      "                    'wasserstein_cost_validation': 0.31653133},\n",
      "                   {'cost': -0.15687773,\n",
      "                    'cost_validation': -0.29791665,\n",
      "                    'wasserstein_cost': 0.18447977,\n",
      "                    'wasserstein_cost_validation': 0.32656607},\n",
      "                   {'cost': -0.21446589,\n",
      "                    'cost_validation': -0.30746472,\n",
      "                    'wasserstein_cost': 0.24506053,\n",
      "                    'wasserstein_cost_validation': 0.33946025},\n",
      "                   {'cost': -0.17642361,\n",
      "                    'cost_validation': -0.3054191,\n",
      "                    'wasserstein_cost': 0.2050507,\n",
      "                    'wasserstein_cost_validation': 0.33518788}],\n",
      " 'generator': {'cost': -0.32499507}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 10\n",
      "{'discriminator': [{'cost': -0.2521128,\n",
      "                    'cost_validation': -0.36676073,\n",
      "                    'wasserstein_cost': 0.2871388,\n",
      "                    'wasserstein_cost_validation': 0.3979575},\n",
      "                   {'cost': -0.2207179,\n",
      "                    'cost_validation': -0.3782377,\n",
      "                    'wasserstein_cost': 0.2547192,\n",
      "                    'wasserstein_cost_validation': 0.41150147},\n",
      "                   {'cost': -0.25752932,\n",
      "                    'cost_validation': -0.38798395,\n",
      "                    'wasserstein_cost': 0.2919979,\n",
      "                    'wasserstein_cost_validation': 0.42256308},\n",
      "                   {'cost': -0.2517787,\n",
      "                    'cost_validation': -0.3905712,\n",
      "                    'wasserstein_cost': 0.28476745,\n",
      "                    'wasserstein_cost_validation': 0.4244362},\n",
      "                   {'cost': -0.26934314,\n",
      "                    'cost_validation': -0.4026487,\n",
      "                    'wasserstein_cost': 0.30498523,\n",
      "                    'wasserstein_cost_validation': 0.43712348}],\n",
      " 'generator': {'cost': -0.27157357}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 11\n",
      "{'discriminator': [{'cost': -0.5568379,\n",
      "                    'cost_validation': -0.6634642,\n",
      "                    'wasserstein_cost': 0.5937814,\n",
      "                    'wasserstein_cost_validation': 0.70730066},\n",
      "                   {'cost': -0.5752457,\n",
      "                    'cost_validation': -0.6697392,\n",
      "                    'wasserstein_cost': 0.61513865,\n",
      "                    'wasserstein_cost_validation': 0.71396685},\n",
      "                   {'cost': -0.59583455,\n",
      "                    'cost_validation': -0.6808303,\n",
      "                    'wasserstein_cost': 0.637972,\n",
      "                    'wasserstein_cost_validation': 0.7205556},\n",
      "                   {'cost': -0.6483335,\n",
      "                    'cost_validation': -0.6819562,\n",
      "                    'wasserstein_cost': 0.6897478,\n",
      "                    'wasserstein_cost_validation': 0.725845},\n",
      "                   {'cost': -0.61407083,\n",
      "                    'cost_validation': -0.6878465,\n",
      "                    'wasserstein_cost': 0.6528503,\n",
      "                    'wasserstein_cost_validation': 0.7335299}],\n",
      " 'generator': {'cost': -0.15199283}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 12\n",
      "{'discriminator': [{'cost': -0.78207564,\n",
      "                    'cost_validation': -0.8201028,\n",
      "                    'wasserstein_cost': 0.82959306,\n",
      "                    'wasserstein_cost_validation': 0.86703074},\n",
      "                   {'cost': -0.79215217,\n",
      "                    'cost_validation': -0.83046377,\n",
      "                    'wasserstein_cost': 0.8382488,\n",
      "                    'wasserstein_cost_validation': 0.8758398},\n",
      "                   {'cost': -0.7926656,\n",
      "                    'cost_validation': -0.831171,\n",
      "                    'wasserstein_cost': 0.84052193,\n",
      "                    'wasserstein_cost_validation': 0.8790265},\n",
      "                   {'cost': -0.8082701,\n",
      "                    'cost_validation': -0.83183604,\n",
      "                    'wasserstein_cost': 0.85563993,\n",
      "                    'wasserstein_cost_validation': 0.883295},\n",
      "                   {'cost': -0.8110868,\n",
      "                    'cost_validation': -0.8410312,\n",
      "                    'wasserstein_cost': 0.8568664,\n",
      "                    'wasserstein_cost_validation': 0.8875425}],\n",
      " 'generator': {'cost': -0.079267114}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 13\n",
      "{'discriminator': [{'cost': -0.42657283,\n",
      "                    'cost_validation': -0.56124187,\n",
      "                    'wasserstein_cost': 0.44790733,\n",
      "                    'wasserstein_cost_validation': 0.594193},\n",
      "                   {'cost': -0.45276728,\n",
      "                    'cost_validation': -0.57998353,\n",
      "                    'wasserstein_cost': 0.4788426,\n",
      "                    'wasserstein_cost_validation': 0.6144633},\n",
      "                   {'cost': -0.4902217,\n",
      "                    'cost_validation': -0.5922566,\n",
      "                    'wasserstein_cost': 0.51435345,\n",
      "                    'wasserstein_cost_validation': 0.62328666},\n",
      "                   {'cost': -0.4663845,\n",
      "                    'cost_validation': -0.60042644,\n",
      "                    'wasserstein_cost': 0.49172658,\n",
      "                    'wasserstein_cost_validation': 0.6306115},\n",
      "                   {'cost': -0.43307906,\n",
      "                    'cost_validation': -0.59928256,\n",
      "                    'wasserstein_cost': 0.45962042,\n",
      "                    'wasserstein_cost_validation': 0.63224703}],\n",
      " 'generator': {'cost': -0.22022665}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 14\n",
      "{'discriminator': [{'cost': -0.0069190897,\n",
      "                    'cost_validation': -0.21320595,\n",
      "                    'wasserstein_cost': 0.044651717,\n",
      "                    'wasserstein_cost_validation': 0.2460711},\n",
      "                   {'cost': -0.08352363,\n",
      "                    'cost_validation': -0.21759406,\n",
      "                    'wasserstein_cost': 0.121389836,\n",
      "                    'wasserstein_cost_validation': 0.25430965},\n",
      "                   {'cost': 0.030889641,\n",
      "                    'cost_validation': -0.23692603,\n",
      "                    'wasserstein_cost': 0.016770333,\n",
      "                    'wasserstein_cost_validation': 0.27091283},\n",
      "                   {'cost': -0.018365953,\n",
      "                    'cost_validation': -0.23992947,\n",
      "                    'wasserstein_cost': 0.06336895,\n",
      "                    'wasserstein_cost_validation': 0.27669948},\n",
      "                   {'cost': -0.027957685,\n",
      "                    'cost_validation': -0.24976319,\n",
      "                    'wasserstein_cost': 0.07468517,\n",
      "                    'wasserstein_cost_validation': 0.2854483}],\n",
      " 'generator': {'cost': -0.20870344}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 15\n",
      "{'discriminator': [{'cost': -0.096647084,\n",
      "                    'cost_validation': -0.3565873,\n",
      "                    'wasserstein_cost': 0.1543244,\n",
      "                    'wasserstein_cost_validation': 0.40100372},\n",
      "                   {'cost': -0.120606124,\n",
      "                    'cost_validation': -0.36600387,\n",
      "                    'wasserstein_cost': 0.1758606,\n",
      "                    'wasserstein_cost_validation': 0.40829837},\n",
      "                   {'cost': -0.18190536,\n",
      "                    'cost_validation': -0.3770084,\n",
      "                    'wasserstein_cost': 0.23668332,\n",
      "                    'wasserstein_cost_validation': 0.4215389},\n",
      "                   {'cost': -0.1365318,\n",
      "                    'cost_validation': -0.38357997,\n",
      "                    'wasserstein_cost': 0.18940376,\n",
      "                    'wasserstein_cost_validation': 0.42760137},\n",
      "                   {'cost': -0.19416349,\n",
      "                    'cost_validation': -0.39907113,\n",
      "                    'wasserstein_cost': 0.24538551,\n",
      "                    'wasserstein_cost_validation': 0.44111156}],\n",
      " 'generator': {'cost': -0.13647977}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 16\n",
      "{'discriminator': [{'cost': -0.59937245,\n",
      "                    'cost_validation': -0.72654885,\n",
      "                    'wasserstein_cost': 0.64428365,\n",
      "                    'wasserstein_cost_validation': 0.7660617},\n",
      "                   {'cost': -0.61895156,\n",
      "                    'cost_validation': -0.72715235,\n",
      "                    'wasserstein_cost': 0.6576114,\n",
      "                    'wasserstein_cost_validation': 0.7739365},\n",
      "                   {'cost': -0.63938534,\n",
      "                    'cost_validation': -0.73496985,\n",
      "                    'wasserstein_cost': 0.6795417,\n",
      "                    'wasserstein_cost_validation': 0.7834021},\n",
      "                   {'cost': -0.681028,\n",
      "                    'cost_validation': -0.7465785,\n",
      "                    'wasserstein_cost': 0.72042364,\n",
      "                    'wasserstein_cost_validation': 0.7928683},\n",
      "                   {'cost': -0.651799,\n",
      "                    'cost_validation': -0.7523495,\n",
      "                    'wasserstein_cost': 0.689958,\n",
      "                    'wasserstein_cost_validation': 0.7985041}],\n",
      " 'generator': {'cost': -0.095788784}}\n",
      "Generating samples...\n",
      "Saving samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n",
      "{'discriminator': [{'cost': -0.88819724,\n",
      "                    'cost_validation': -0.89630985,\n",
      "                    'wasserstein_cost': 0.94671655,\n",
      "                    'wasserstein_cost_validation': 0.9565772},\n",
      "                   {'cost': -0.87803197,\n",
      "                    'cost_validation': -0.8865394,\n",
      "                    'wasserstein_cost': 0.93582064,\n",
      "                    'wasserstein_cost_validation': 0.9578913},\n",
      "                   {'cost': -0.8963539,\n",
      "                    'cost_validation': -0.8916712,\n",
      "                    'wasserstein_cost': 0.94870913,\n",
      "                    'wasserstein_cost_validation': 0.95967853},\n",
      "                   {'cost': -0.890278,\n",
      "                    'cost_validation': -0.90520835,\n",
      "                    'wasserstein_cost': 0.948708,\n",
      "                    'wasserstein_cost_validation': 0.96100515},\n",
      "                   {'cost': -0.89131445,\n",
      "                    'cost_validation': -0.9005831,\n",
      "                    'wasserstein_cost': 0.9430837,\n",
      "                    'wasserstein_cost_validation': 0.96274006}],\n",
      " 'generator': {'cost': -0.022642339}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 18\n",
      "{'discriminator': [{'cost': -0.9196426,\n",
      "                    'cost_validation': -0.92204726,\n",
      "                    'wasserstein_cost': 0.9880368,\n",
      "                    'wasserstein_cost_validation': 0.9909677},\n",
      "                   {'cost': -0.9294853,\n",
      "                    'cost_validation': -0.92166126,\n",
      "                    'wasserstein_cost': 0.98848844,\n",
      "                    'wasserstein_cost_validation': 0.9914236},\n",
      "                   {'cost': -0.926607,\n",
      "                    'cost_validation': -0.9168672,\n",
      "                    'wasserstein_cost': 0.98872364,\n",
      "                    'wasserstein_cost_validation': 0.991752},\n",
      "                   {'cost': -0.9248761,\n",
      "                    'cost_validation': -0.9256462,\n",
      "                    'wasserstein_cost': 0.98892796,\n",
      "                    'wasserstein_cost_validation': 0.9918776},\n",
      "                   {'cost': -0.922126,\n",
      "                    'cost_validation': -0.92138857,\n",
      "                    'wasserstein_cost': 0.98879856,\n",
      "                    'wasserstein_cost_validation': 0.99225634}],\n",
      " 'generator': {'cost': -0.0054247393}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 19\n",
      "{'discriminator': [{'cost': -0.92003846,\n",
      "                    'cost_validation': -0.9266522,\n",
      "                    'wasserstein_cost': 0.99407005,\n",
      "                    'wasserstein_cost_validation': 0.99533296},\n",
      "                   {'cost': -0.9272008,\n",
      "                    'cost_validation': -0.9193472,\n",
      "                    'wasserstein_cost': 0.9943024,\n",
      "                    'wasserstein_cost_validation': 0.9951337},\n",
      "                   {'cost': -0.936811,\n",
      "                    'cost_validation': -0.9310662,\n",
      "                    'wasserstein_cost': 0.9936625,\n",
      "                    'wasserstein_cost_validation': 0.99510103},\n",
      "                   {'cost': -0.92248636,\n",
      "                    'cost_validation': -0.92431426,\n",
      "                    'wasserstein_cost': 0.993759,\n",
      "                    'wasserstein_cost_validation': 0.9951276},\n",
      "                   {'cost': -0.9284965,\n",
      "                    'cost_validation': -0.9280164,\n",
      "                    'wasserstein_cost': 0.9937072,\n",
      "                    'wasserstein_cost_validation': 0.99548596}],\n",
      " 'generator': {'cost': -0.003291625}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 20\n",
      "{'discriminator': [{'cost': -0.9322003,\n",
      "                    'cost_validation': -0.9299866,\n",
      "                    'wasserstein_cost': 0.9926023,\n",
      "                    'wasserstein_cost_validation': 0.9944581},\n",
      "                   {'cost': -0.9356058,\n",
      "                    'cost_validation': -0.92598945,\n",
      "                    'wasserstein_cost': 0.9934054,\n",
      "                    'wasserstein_cost_validation': 0.9950052},\n",
      "                   {'cost': -0.9334206,\n",
      "                    'cost_validation': -0.9310464,\n",
      "                    'wasserstein_cost': 0.9941503,\n",
      "                    'wasserstein_cost_validation': 0.9950598},\n",
      "                   {'cost': -0.9297632,\n",
      "                    'cost_validation': -0.93223214,\n",
      "                    'wasserstein_cost': 0.9938677,\n",
      "                    'wasserstein_cost_validation': 0.99528897},\n",
      "                   {'cost': -0.92989284,\n",
      "                    'cost_validation': -0.93562394,\n",
      "                    'wasserstein_cost': 0.99416137,\n",
      "                    'wasserstein_cost_validation': 0.9950382}],\n",
      " 'generator': {'cost': -0.003787164}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 21\n",
      "{'discriminator': [{'cost': -0.93880147,\n",
      "                    'cost_validation': -0.93083376,\n",
      "                    'wasserstein_cost': 0.9899467,\n",
      "                    'wasserstein_cost_validation': 0.9917962},\n",
      "                   {'cost': -0.9344294,\n",
      "                    'cost_validation': -0.9296488,\n",
      "                    'wasserstein_cost': 0.99091184,\n",
      "                    'wasserstein_cost_validation': 0.99228936},\n",
      "                   {'cost': -0.93524855,\n",
      "                    'cost_validation': -0.9295335,\n",
      "                    'wasserstein_cost': 0.99109674,\n",
      "                    'wasserstein_cost_validation': 0.99292356},\n",
      "                   {'cost': -0.9349724,\n",
      "                    'cost_validation': -0.93383086,\n",
      "                    'wasserstein_cost': 0.99069554,\n",
      "                    'wasserstein_cost_validation': 0.99320644},\n",
      "                   {'cost': -0.9337958,\n",
      "                    'cost_validation': -0.9352752,\n",
      "                    'wasserstein_cost': 0.9914639,\n",
      "                    'wasserstein_cost_validation': 0.99343765}],\n",
      " 'generator': {'cost': -0.004221508}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 22\n",
      "{'discriminator': [{'cost': -0.910274,\n",
      "                    'cost_validation': -0.9179005,\n",
      "                    'wasserstein_cost': 0.9536805,\n",
      "                    'wasserstein_cost_validation': 0.9641777},\n",
      "                   {'cost': -0.9142286,\n",
      "                    'cost_validation': -0.92640203,\n",
      "                    'wasserstein_cost': 0.95428455,\n",
      "                    'wasserstein_cost_validation': 0.96707666},\n",
      "                   {'cost': -0.9131312,\n",
      "                    'cost_validation': -0.92128223,\n",
      "                    'wasserstein_cost': 0.9596911,\n",
      "                    'wasserstein_cost_validation': 0.9697588},\n",
      "                   {'cost': -0.91703,\n",
      "                    'cost_validation': -0.9256565,\n",
      "                    'wasserstein_cost': 0.9624072,\n",
      "                    'wasserstein_cost_validation': 0.97041416},\n",
      "                   {'cost': -0.91843563,\n",
      "                    'cost_validation': -0.9285068,\n",
      "                    'wasserstein_cost': 0.96154845,\n",
      "                    'wasserstein_cost_validation': 0.9730888}],\n",
      " 'generator': {'cost': -0.01823794}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 23\n",
      "{'discriminator': [{'cost': 0.35360634,\n",
      "                    'cost_validation': 0.18708435,\n",
      "                    'wasserstein_cost': -0.33714643,\n",
      "                    'wasserstein_cost_validation': -0.17551798},\n",
      "                   {'cost': 0.42124334,\n",
      "                    'cost_validation': 0.17252204,\n",
      "                    'wasserstein_cost': -0.40581733,\n",
      "                    'wasserstein_cost_validation': -0.1617006},\n",
      "                   {'cost': 0.3003875,\n",
      "                    'cost_validation': 0.13810821,\n",
      "                    'wasserstein_cost': -0.29127288,\n",
      "                    'wasserstein_cost_validation': -0.12778667},\n",
      "                   {'cost': 0.34303683,\n",
      "                    'cost_validation': 0.13487257,\n",
      "                    'wasserstein_cost': -0.32779938,\n",
      "                    'wasserstein_cost_validation': -0.12389684},\n",
      "                   {'cost': 0.2684254,\n",
      "                    'cost_validation': 0.10445854,\n",
      "                    'wasserstein_cost': -0.2557707,\n",
      "                    'wasserstein_cost_validation': -0.09217435}],\n",
      " 'generator': {'cost': -0.53276986}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 24\n",
      "{'discriminator': [{'cost': 0.08674684,\n",
      "                    'cost_validation': 0.061089706,\n",
      "                    'wasserstein_cost': -6.621331e-05,\n",
      "                    'wasserstein_cost_validation': 0.020226587},\n",
      "                   {'cost': 0.11476977,\n",
      "                    'cost_validation': 0.060825896,\n",
      "                    'wasserstein_cost': -0.029613398,\n",
      "                    'wasserstein_cost_validation': 0.017191079},\n",
      "                   {'cost': 0.10932255,\n",
      "                    'cost_validation': 0.055185653,\n",
      "                    'wasserstein_cost': -0.02168974,\n",
      "                    'wasserstein_cost_validation': 0.02724354},\n",
      "                   {'cost': 0.113080315,\n",
      "                    'cost_validation': 0.055917095,\n",
      "                    'wasserstein_cost': -0.023187049,\n",
      "                    'wasserstein_cost_validation': 0.026862483},\n",
      "                   {'cost': 0.09088963,\n",
      "                    'cost_validation': 0.05620701,\n",
      "                    'wasserstein_cost': -0.004376497,\n",
      "                    'wasserstein_cost_validation': 0.025467671}],\n",
      " 'generator': {'cost': -0.040203992}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'discriminator': [{'cost': -0.12758227,\n",
      "                    'cost_validation': -0.36566994,\n",
      "                    'wasserstein_cost': 0.17677683,\n",
      "                    'wasserstein_cost_validation': 0.40435892},\n",
      "                   {'cost': -0.19305474,\n",
      "                    'cost_validation': -0.37851155,\n",
      "                    'wasserstein_cost': 0.23890017,\n",
      "                    'wasserstein_cost_validation': 0.41833204},\n",
      "                   {'cost': -0.13618144,\n",
      "                    'cost_validation': -0.38949394,\n",
      "                    'wasserstein_cost': 0.18935573,\n",
      "                    'wasserstein_cost_validation': 0.42647716},\n",
      "                   {'cost': -0.1631788,\n",
      "                    'cost_validation': -0.40211096,\n",
      "                    'wasserstein_cost': 0.20837969,\n",
      "                    'wasserstein_cost_validation': 0.43738747},\n",
      "                   {'cost': -0.16414826,\n",
      "                    'cost_validation': -0.41863465,\n",
      "                    'wasserstein_cost': 0.21105352,\n",
      "                    'wasserstein_cost_validation': 0.45301238}],\n",
      " 'generator': {'cost': -0.08240557}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 26\n",
      "{'discriminator': [{'cost': -0.7154,\n",
      "                    'cost_validation': -0.7936993,\n",
      "                    'wasserstein_cost': 0.7398465,\n",
      "                    'wasserstein_cost_validation': 0.8392179},\n",
      "                   {'cost': -0.69719225,\n",
      "                    'cost_validation': -0.80613774,\n",
      "                    'wasserstein_cost': 0.721738,\n",
      "                    'wasserstein_cost_validation': 0.8461153},\n",
      "                   {'cost': -0.7487579,\n",
      "                    'cost_validation': -0.80951834,\n",
      "                    'wasserstein_cost': 0.7773576,\n",
      "                    'wasserstein_cost_validation': 0.849911},\n",
      "                   {'cost': -0.75468534,\n",
      "                    'cost_validation': -0.81611174,\n",
      "                    'wasserstein_cost': 0.77523875,\n",
      "                    'wasserstein_cost_validation': 0.8599308},\n",
      "                   {'cost': -0.77904665,\n",
      "                    'cost_validation': -0.81999755,\n",
      "                    'wasserstein_cost': 0.80868065,\n",
      "                    'wasserstein_cost_validation': 0.86342233}],\n",
      " 'generator': {'cost': -0.07827986}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 27\n",
      "{'discriminator': [{'cost': -0.760908,\n",
      "                    'cost_validation': -0.7949915,\n",
      "                    'wasserstein_cost': 0.78382295,\n",
      "                    'wasserstein_cost_validation': 0.8394511},\n",
      "                   {'cost': -0.75464195,\n",
      "                    'cost_validation': -0.814919,\n",
      "                    'wasserstein_cost': 0.77810246,\n",
      "                    'wasserstein_cost_validation': 0.86115205},\n",
      "                   {'cost': -0.77482414,\n",
      "                    'cost_validation': -0.82230675,\n",
      "                    'wasserstein_cost': 0.8027177,\n",
      "                    'wasserstein_cost_validation': 0.8582878},\n",
      "                   {'cost': -0.7526592,\n",
      "                    'cost_validation': -0.8149538,\n",
      "                    'wasserstein_cost': 0.7785839,\n",
      "                    'wasserstein_cost_validation': 0.85748965},\n",
      "                   {'cost': -0.74601066,\n",
      "                    'cost_validation': -0.8208055,\n",
      "                    'wasserstein_cost': 0.7731417,\n",
      "                    'wasserstein_cost_validation': 0.85503405}],\n",
      " 'generator': {'cost': -0.09509574}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 28\n",
      "{'discriminator': [{'cost': -0.4973761,\n",
      "                    'cost_validation': -0.6615243,\n",
      "                    'wasserstein_cost': 0.5152014,\n",
      "                    'wasserstein_cost_validation': 0.6935489},\n",
      "                   {'cost': -0.4840049,\n",
      "                    'cost_validation': -0.66622823,\n",
      "                    'wasserstein_cost': 0.5038052,\n",
      "                    'wasserstein_cost_validation': 0.697135},\n",
      "                   {'cost': -0.504352,\n",
      "                    'cost_validation': -0.6756788,\n",
      "                    'wasserstein_cost': 0.5301485,\n",
      "                    'wasserstein_cost_validation': 0.69985974},\n",
      "                   {'cost': -0.5018536,\n",
      "                    'cost_validation': -0.67144793,\n",
      "                    'wasserstein_cost': 0.5229649,\n",
      "                    'wasserstein_cost_validation': 0.69980395},\n",
      "                   {'cost': -0.45437393,\n",
      "                    'cost_validation': -0.68059003,\n",
      "                    'wasserstein_cost': 0.47720993,\n",
      "                    'wasserstein_cost_validation': 0.7042701}],\n",
      " 'generator': {'cost': -0.13518052}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 29\n",
      "{'discriminator': [{'cost': -0.63960254,\n",
      "                    'cost_validation': -0.7218623,\n",
      "                    'wasserstein_cost': 0.6612233,\n",
      "                    'wasserstein_cost_validation': 0.755159},\n",
      "                   {'cost': -0.6059042,\n",
      "                    'cost_validation': -0.74657,\n",
      "                    'wasserstein_cost': 0.62582606,\n",
      "                    'wasserstein_cost_validation': 0.7765167},\n",
      "                   {'cost': -0.6417544,\n",
      "                    'cost_validation': -0.7536577,\n",
      "                    'wasserstein_cost': 0.6647638,\n",
      "                    'wasserstein_cost_validation': 0.7847917},\n",
      "                   {'cost': -0.60142577,\n",
      "                    'cost_validation': -0.7569244,\n",
      "                    'wasserstein_cost': 0.62508494,\n",
      "                    'wasserstein_cost_validation': 0.792912},\n",
      "                   {'cost': -0.6708287,\n",
      "                    'cost_validation': -0.76305485,\n",
      "                    'wasserstein_cost': 0.68697035,\n",
      "                    'wasserstein_cost_validation': 0.7966761}],\n",
      " 'generator': {'cost': -0.104329996}}\n",
      "Generating samples...\n",
      "Saving samples...\n",
      "Epoch: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Starting training...')\n",
    "model_gen, model_dis, history, final_discr_metrics, samples = train_wgan(\n",
    "    model_gen=model_gen,\n",
    "    model_dis=model_dis,\n",
    "    train_gen=train_gen,\n",
    "    valid_data=valid_data,\n",
    "    test_data=test_data,\n",
    "    num_epochs=num_epochs,\n",
    "    batches_per_epoch=batches_per_epoch,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=model_dir,\n",
    "    lr=learning_rate,\n",
    "    beta_1=beta_one,\n",
    "    beta_2=beta_two,\n",
    "    use_cuda=ngpus>=1,\n",
    "    discriminator_updates=discriminator_updates,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs_per_sample=epochs_per_sample,\n",
    "    sample_size=sample_size)\n",
    "\n",
    "print('Finished training.')\n",
    "\n",
    "print('Final discriminator loss on validation and test:')\n",
    "print(pprint.pformat(final_discr_metrics))\n",
    "\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Starting training...')\n",
    "model_gen2, model_dis, history, final_discr_metrics, samples = train_wgan(\n",
    "    model_gen=model_gen2,\n",
    "    model_dis=model_dis,\n",
    "    train_gen=train_gen,\n",
    "    valid_data=valid_data,\n",
    "    test_data=test_data,\n",
    "    num_epochs=num_epochs,\n",
    "    batches_per_epoch=batches_per_epoch,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=model_dir,\n",
    "    lr=learning_rate,\n",
    "    beta_1=beta_one,\n",
    "    beta_2=beta_two,\n",
    "    use_cuda=ngpus>=1,\n",
    "    discriminator_updates=discriminator_updates,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs_per_sample=epochs_per_sample,\n",
    "    sample_size=sample_size)\n",
    "\n",
    "print('Finished training.')\n",
    "\n",
    "print('Final discriminator loss on validation and test:')\n",
    "print(pprint.pformat(final_discr_metrics))\n",
    "\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
