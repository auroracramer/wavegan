{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import os\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import pescador\n",
    "import librosa\n",
    "import pprint\n",
    "from IPython.display import Audio\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
    "    by a random integer in {-n, n} and performing reflection padding where\n",
    "    necessary\n",
    "\n",
    "    If batch shuffle is enabled, only a single shuffle is applied to the entire\n",
    "    batch, rather than each sample in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shift_factor, batch_shuffle=False):\n",
    "        super(PhaseShuffle, self).__init__()\n",
    "        self.shift_factor = shift_factor\n",
    "        self.batch_shuffle = batch_shuffle\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Return x if phase shift is disabled\n",
    "        if self.shift_factor == 0:\n",
    "            return x\n",
    "\n",
    "        if self.batch_shuffle:\n",
    "            # Make sure to use PyTorcTrueh to generate number RNG state is all shared\n",
    "            k = int(torch.Tensor(1).random_(0, 2*self.shift_factor + 1)) - self.shift_factor\n",
    "\n",
    "            # Return if no phase shift\n",
    "            if k == 0:\n",
    "                return x\n",
    "\n",
    "            # Slice feature dimension\n",
    "            if k > 0:\n",
    "                x_trunc = x[:, :, :-k]\n",
    "                pad = (k, 0)\n",
    "            else:\n",
    "                x_trunc = x[:, :, -k:]\n",
    "                pad = (0, -k)\n",
    "\n",
    "            # Reflection padding\n",
    "            x_shuffle = F.pad(x_trunc, pad, mode='reflect')\n",
    "\n",
    "        else:\n",
    "            # Generate shifts for each sample in the batch\n",
    "            k_list = torch.Tensor(x.shape[0]).random_(0, 2*self.shift_factor+1)\\\n",
    "                - self.shift_factor\n",
    "            k_list = k_list.numpy().astype(int)\n",
    "\n",
    "            # Combine sample indices into lists so that less shuffle operations\n",
    "            # need to be performed\n",
    "            k_map = {}\n",
    "            for idx, k in enumerate(k_list):\n",
    "                k = int(k)\n",
    "                if k not in k_map:\n",
    "                    k_map[k] = []\n",
    "                k_map[k].append(idx)\n",
    "\n",
    "            # Make a copy of x for our output\n",
    "            x_shuffle = x.clone()\n",
    "\n",
    "            # Apply shuffle to each sample\n",
    "            for k, idxs in k_map.items():\n",
    "                if k > 0:\n",
    "                    x_shuffle[idxs] = F.pad(x[idxs][..., :-k], (k,0), mode='reflect')\n",
    "                else:\n",
    "                    x_shuffle[idxs] = F.pad(x[idxs][..., -k:], (0,-k), mode='reflect')\n",
    "\n",
    "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape,\n",
    "                                                           x.shape)\n",
    "        return x_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        if upsample:\n",
    "            self.upsample_layer = torch.nn.Upsample(scale_factor=upsample)\n",
    "            reflection_padding = kernel_size // 2\n",
    "            self.reflection_pad = torch.nn.ReflectionPad1d(reflection_padding)\n",
    "            self.conv1d = torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = self.upsample_layer(x_in)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv1d(out)\n",
    "        return out\n",
    "\n",
    "class WaveGANGenerator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, latent_dim=100,\n",
    "                 post_proc_filt_len=512, verbose=False, upsample=True):\n",
    "        super(WaveGANGenerator, self).__init__()\n",
    "        self.ngpus = ngpus\n",
    "        self.model_size = model_size # d\n",
    "        self.num_channels = num_channels # c\n",
    "        self.latent_dim = latent_dim\n",
    "        self.post_proc_filt_len = post_proc_filt_len\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(latent_dim, 256 * model_size))\n",
    "        \n",
    "        self.tconv1 = None\n",
    "        self.tconv2 = None\n",
    "        self.tconv3 = None\n",
    "        self.tconv4 = None\n",
    "        self.tconv5 = None\n",
    "        \n",
    "                \n",
    "        self.upSampConv1 = None\n",
    "        self.upSampConv2 = None\n",
    "        self.upSampConv3 = None\n",
    "        self.upSampConv4 = None\n",
    "        self.upSampConv5 = None\n",
    "        \n",
    "        self.upsample = upsample\n",
    "    \n",
    "        if self.upsample:\n",
    "            self.upSampConv1 = nn.DataParallel(\n",
    "                UpsampleConvLayer(16 * model_size, 8 * model_size, 25, stride=4, upsample=4))\n",
    "            self.upSampConv2 = nn.DataParallel(\n",
    "                UpsampleConvLayer(8 * model_size, 4 * model_size, 25, stride=4, upsample=4))\n",
    "            self.upSampConv3 = nn.DataParallel(\n",
    "                UpsampleConvLayer(4 * model_size, 2 * model_size, 25, stride=4, upsample=4))\n",
    "            self.upSampConv4 = nn.DataParallel(\n",
    "                UpsampleConvLayer(2 * model_size, model_size, 25, stride=4, upsample=4))\n",
    "            self.upSampConv5 = nn.DataParallel(\n",
    "                UpsampleConvLayer(model_size, num_channels, 25, stride=4, upsample=4))\n",
    "            \n",
    "        else:\n",
    "            self.tconv1 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(16 * model_size, 8 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv2 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(8 * model_size, 4 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv3 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(4 * model_size, 2 * model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv4 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(2 * model_size, model_size, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "            self.tconv5 = nn.DataParallel(\n",
    "                nn.ConvTranspose1d(model_size, num_channels, 25, stride=4, padding=11,\n",
    "                                   output_padding=1))\n",
    "\n",
    "        if post_proc_filt_len:\n",
    "            self.ppfilter1 = nn.DataParallel(nn.Conv1d(num_channels, num_channels, post_proc_filt_len))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x).view(-1, 16 * self.model_size, 16)\n",
    "        x = F.relu(x)\n",
    "        output = None\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        \n",
    "        if self.upsample:\n",
    "            x = F.relu(self.upSampConv1(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv2(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv3(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.upSampConv4(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            output = F.tanh(self.upSampConv5(x))\n",
    "        else:\n",
    "            x = F.relu(self.tconv1(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv2(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv3(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            x = F.relu(self.tconv4(x))\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "\n",
    "            output = F.tanh(self.tconv5(x))\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(output.shape)\n",
    "\n",
    "        if self.post_proc_filt_len:\n",
    "            # Pad for \"same\" filtering\n",
    "            if (self.post_proc_filt_len % 2) == 0:\n",
    "                pad_left = self.post_proc_filt_len // 2\n",
    "                pad_right = pad_left - 1\n",
    "            else:\n",
    "                pad_left = (self.post_proc_filt_len - 1) // 2\n",
    "                pad_right = pad_left\n",
    "            output = self.ppfilter1(F.pad(output, (pad_left, pad_right)))\n",
    "            if self.verbose:\n",
    "                print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class WaveGANDiscriminator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2, alpha=0.2, batch_shuffle=False, verbose=False):\n",
    "        super(WaveGANDiscriminator, self).__init__()\n",
    "        self.model_size = model_size # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels # c\n",
    "        self.shift_factor = shift_factor # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, etc.)\n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "        self.ps1 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps2 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps3 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps4 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, 1))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps4(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        return F.sigmoid(self.fc1(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavegan_generator(filepath, model_size=64, ngpus=1, num_channels=1,\n",
    "                           latent_dim=100, post_proc_filt_len=512, **kwargs):\n",
    "    model = WaveGANGenerator(model_size=model_size, ngpus=ngpus,\n",
    "                             num_channels=num_channels, latent_dim=latent_dim,\n",
    "                             post_proc_filt_len=post_proc_filt_len)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_wavegan_discriminator(filepath, model_size=64, ngpus=1, num_channels=1,\n",
    "                               shift_factor=2, alpha=0.2, **kwargs):\n",
    "    model = WaveGANDiscriminator(model_size=model_size, ngpus=ngpus,\n",
    "                                 num_channels=num_channels,\n",
    "                                 shift_factor=shift_factor, alpha=alpha)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discr_loss_terms(model_dis, model_gen, real_data_v, noise_v,\n",
    "                             batch_size, latent_dim,\n",
    "                             lmbda, use_cuda, compute_grads=False):\n",
    "    # Convenient values for\n",
    "    one = torch.FloatTensor([1])\n",
    "    neg_one = one * -1\n",
    "    if use_cuda:\n",
    "        one = one.cuda()\n",
    "        neg_one = neg_one.cuda()\n",
    "\n",
    "    # Reset gradients\n",
    "    model_dis.zero_grad()\n",
    "\n",
    "    # a) Compute loss contribution from real training data and backprop\n",
    "    # (negative of the empirical mean, w.r.t. the data distribution, of the discr. output)\n",
    "    D_real = model_dis(real_data_v)\n",
    "    D_real = D_real.mean()\n",
    "    # Negate since we want to _maximize_ this quantity\n",
    "    if compute_grads:\n",
    "        D_real.backward(neg_one)\n",
    "\n",
    "    # b) Compute loss contribution from generated data and backprop\n",
    "    # (empirical mean, w.r.t. the generator distribution, of the discr. output)\n",
    "    # Generate noise in latent space\n",
    "\n",
    "    # Generate data by passing noise through the generator\n",
    "    fake = autograd.Variable(model_gen(noise_v).data)\n",
    "    inputv = fake\n",
    "    D_fake = model_dis(inputv)\n",
    "    D_fake = D_fake.mean()\n",
    "    if compute_grads:\n",
    "        D_fake.backward(one)\n",
    "\n",
    "    # c) Compute gradient penalty and backprop\n",
    "    gradient_penalty = calc_gradient_penalty(model_dis, real_data_v.data,\n",
    "                                             fake.data,\n",
    "                                             batch_size, lmbda,\n",
    "                                             use_cuda=use_cuda)\n",
    "\n",
    "    if compute_grads:\n",
    "        gradient_penalty.backward(one)\n",
    "\n",
    "    # Compute metrics and record in batch history\n",
    "    D_cost = D_fake - D_real + gradient_penalty\n",
    "    Wasserstein_D = D_real - D_fake\n",
    "\n",
    "    return D_cost, Wasserstein_D\n",
    "\n",
    "\n",
    "def compute_gener_loss_terms(model_dis, model_gen, batch_size, latent_dim,\n",
    "                             use_cuda, compute_grads=False):\n",
    "    # Convenient values for\n",
    "    one = torch.FloatTensor([1])\n",
    "    neg_one = one * -1\n",
    "    if use_cuda:\n",
    "        one = one.cuda()\n",
    "        neg_one = neg_one.cuda()\n",
    "\n",
    "    # Reset generator gradients\n",
    "    model_gen.zero_grad()\n",
    "\n",
    "    # Sample from the generator\n",
    "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda()\n",
    "    noise_v = autograd.Variable(noise)\n",
    "    fake = model_gen(noise_v)\n",
    "\n",
    "    # Compute generator loss and backprop\n",
    "    # (negative of empirical mean (w.r.t generator distribution) of discriminator output)\n",
    "    G = model_dis(fake)\n",
    "    G = G.mean()\n",
    "    if compute_grads:\n",
    "        G.backward(neg_one)\n",
    "    G_cost = -G\n",
    "\n",
    "    return G_cost\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sample_generator(filepath, window_length=16384, fs=16000):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(filepath, sr=fs)\n",
    "\n",
    "        # Clip amplitude\n",
    "        max_amp = np.max(np.abs(audio_data))\n",
    "        if max_amp > 1:\n",
    "            audio_data /= max_amp\n",
    "    except Exception as e:\n",
    "        print('Could not load {}: {}'.format(filepath, str(e)))\n",
    "        raise StopIteration()\n",
    "\n",
    "    audio_len = len(audio_data)\n",
    "\n",
    "    # Pad audio to at least a single frame\n",
    "    if audio_len < window_length:\n",
    "        pad_length = window_length - audio_len\n",
    "        left_pad = pad_length // 2\n",
    "        right_pad = pad_length - left_pad\n",
    "\n",
    "        audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
    "        audio_len = len(audio_data)\n",
    "\n",
    "    while True:\n",
    "        if audio_len == window_length:\n",
    "            # If we only have a single frame's worth of audio, just yield the whole audio\n",
    "            sample = audio_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0, audio_len - window_length)\n",
    "            end_idx = start_idx + window_length\n",
    "            sample = audio_data[start_idx:end_idx]\n",
    "\n",
    "        sample = sample.astype('float32')\n",
    "        assert not np.any(np.isnan(sample))\n",
    "\n",
    "        yield {'X': sample}\n",
    "\n",
    "\n",
    "def create_batch_generator(audio_filepath_list, batch_size):\n",
    "    streamers = []\n",
    "    for audio_filepath in audio_filepath_list:\n",
    "        s = pescador.Streamer(file_sample_generator, audio_filepath)\n",
    "        streamers.append(s)\n",
    "\n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "\n",
    "    return batch_gen\n",
    "\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir, followlinks=True)\n",
    "            for fname in file_names\n",
    "            if (fname.lower().endswith('.wav') or fname.lower().endswith('.mp3'))]\n",
    "\n",
    "\n",
    "def create_data_split(audio_filepath_list, valid_ratio, test_ratio,\n",
    "                      train_batch_size, valid_size, test_size):\n",
    "    num_files = len(audio_filepath_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "\n",
    "    assert num_valid > 0\n",
    "    assert num_test > 0\n",
    "    assert num_train > 0\n",
    "\n",
    "    valid_files = audio_filepath_list[:num_valid]\n",
    "    test_files = audio_filepath_list[num_valid:num_valid + num_test]\n",
    "    train_files = audio_filepath_list[num_valid + num_test:]\n",
    "\n",
    "    train_gen = create_batch_generator(train_files, train_batch_size)\n",
    "    valid_data = next(iter(create_batch_generator(valid_files, valid_size)))\n",
    "    test_data = next(iter(create_batch_generator(test_files, test_size)))\n",
    "\n",
    "    return train_gen, valid_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(epoch_samples, epoch, output_dir, fs=16000):\n",
    "    \"\"\"\n",
    "    Save output samples to disk\n",
    "    \"\"\"\n",
    "    sample_dir = os.path.join(output_dir, str(epoch))\n",
    "    if not os.path.exists(sample_dir):\n",
    "        os.makedirs(sample_dir)\n",
    "\n",
    "    for idx, samp in enumerate(epoch_samples):\n",
    "        output_path = os.path.join(sample_dir, \"{}.wav\".format(idx+1))\n",
    "        samp = samp[0]\n",
    "        librosa.output.write_wav(output_path, samp, fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_input_var(data, use_cuda):\n",
    "    data = data[:,np.newaxis,:]\n",
    "    data = torch.Tensor(data)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    return autograd.Variable(data)\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def calc_gradient_penalty(model_dis, real_data, fake_data, batch_size, lmbda, use_cuda=True):\n",
    "    # Compute interpolation factors\n",
    "    alpha = torch.rand(batch_size, 1, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda() if use_cuda else alpha\n",
    "\n",
    "    # Interpolate between real and fake data\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    # Evaluate discriminator\n",
    "    disc_interpolates = model_dis(interpolates)\n",
    "\n",
    "    # Obtain gradients of the discriminator with respect to the inputs\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else torch.ones(\n",
    "                                  disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    # Compute MSE between 1.0 and the gradient of the norm penalty to encourage discriminator\n",
    "    # to be a 1-Lipschitz function\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lmbda\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
    "def train_wgan(model_gen, model_dis, train_gen, valid_data, test_data,\n",
    "               num_epochs, batches_per_epoch, batch_size, output_dir=None,\n",
    "               lmbda=0.1, use_cuda=True, discriminator_updates=5, epochs_per_sample=10,\n",
    "               sample_size=20, lr=1e-4, beta_1=0.5, beta_2=0.9, latent_dim=100):\n",
    "\n",
    "    if use_cuda:\n",
    "        model_gen = model_gen.cuda()\n",
    "        model_dis = model_dis.cuda()\n",
    "\n",
    "    # Initialize optimizers for each model\n",
    "    optimizer_gen = optim.Adam(model_gen.parameters(), lr=lr,\n",
    "                               betas=(beta_1, beta_2))\n",
    "    optimizer_dis = optim.Adam(model_dis.parameters(), lr=lr,\n",
    "                               betas=(beta_1, beta_2))\n",
    "\n",
    "    # Sample noise used for seeing the evolution of generated output samples throughout training\n",
    "    sample_noise = torch.Tensor(sample_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        sample_noise = sample_noise.cuda()\n",
    "    sample_noise_v = autograd.Variable(sample_noise)\n",
    "\n",
    "    samples = {}\n",
    "    history = []\n",
    "\n",
    "    train_iter = iter(train_gen)\n",
    "    valid_data_v = np_to_input_var(valid_data['X'], use_cuda)\n",
    "    test_data_v = np_to_input_var(test_data['X'], use_cuda)\n",
    "\n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch+1)) \n",
    "\n",
    "        epoch_history = []\n",
    "\n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "\n",
    "            # Set model parameters to require gradients to be computed and stored\n",
    "            for p in model_dis.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            # Initialize the metrics for this batch\n",
    "            batch_history = {\n",
    "                'discriminator': [],\n",
    "                'generator': {}\n",
    "            }\n",
    "\n",
    "            # Discriminator Training Phase:\n",
    "            # -> Train discriminator k times\n",
    "            for iter_d in range(discriminator_updates):\n",
    "                # Get real examples\n",
    "                real_data_v = np_to_input_var(next(train_iter)['X'], use_cuda)\n",
    "\n",
    "                # Get noise\n",
    "                noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "                if use_cuda:\n",
    "                    noise = noise.cuda()\n",
    "                noise_v = autograd.Variable(noise,\n",
    "                                            volatile=True)  # totally freeze model_gen\n",
    "\n",
    "                # Get new batch of real training data\n",
    "                D_cost_train, D_wass_train = compute_discr_loss_terms(\n",
    "                    model_dis, model_gen, real_data_v, noise_v, batch_size,\n",
    "                    latent_dim,\n",
    "                    lmbda, use_cuda, compute_grads=True)\n",
    "\n",
    "                # Update the discriminator\n",
    "                optimizer_dis.step()\n",
    "\n",
    "                D_cost_valid, D_wass_valid = compute_discr_loss_terms(\n",
    "                    model_dis, model_gen, valid_data_v, noise_v, batch_size,\n",
    "                    latent_dim,\n",
    "                    lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "                if use_cuda:\n",
    "                    D_cost_train = D_cost_train.cpu()\n",
    "                    D_cost_valid = D_cost_valid.cpu()\n",
    "                    D_wass_train = D_wass_train.cpu()\n",
    "                    D_wass_valid = D_wass_valid.cpu()\n",
    "\n",
    "                batch_history['discriminator'].append({\n",
    "                    'cost': D_cost_train.data.numpy()[0],\n",
    "                    'wasserstein_cost': D_wass_train.data.numpy()[0],\n",
    "                    'cost_validation': D_cost_valid.data.numpy()[0],\n",
    "                    'wasserstein_cost_validation': D_wass_valid.data.numpy()[0]\n",
    "                })\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "            # Prevent discriminator from computing gradients, since\n",
    "            # we are only updating the generator\n",
    "            for p in model_dis.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            G_cost = compute_gener_loss_terms(model_dis, model_gen, batch_size,\n",
    "                                              latent_dim,\n",
    "                                              use_cuda, compute_grads=True)\n",
    "\n",
    "            # Update generator\n",
    "            optimizer_gen.step()\n",
    "\n",
    "            if use_cuda:\n",
    "                G_cost = G_cost.cpu()\n",
    "\n",
    "            # Record generator loss\n",
    "            batch_history['generator']['cost'] = G_cost.data.numpy()[0]\n",
    "\n",
    "            # Record batch metrics\n",
    "            epoch_history.append(batch_history)\n",
    "\n",
    "        # Record epoch metrics\n",
    "        history.append(epoch_history)\n",
    "\n",
    "        print(pprint.pformat(epoch_history[-1]))\n",
    "\n",
    "        if (epoch + 1) % epochs_per_sample == 0:\n",
    "            # Generate outputs for fixed latent samples\n",
    "            print('Generating samples...')\n",
    "            samp_output = model_gen(sample_noise_v)\n",
    "            if use_cuda:\n",
    "                samp_output = samp_output.cpu()\n",
    "\n",
    "            samples[epoch+1] = samp_output.data.numpy()\n",
    "            if output_dir:\n",
    "                print('Saving samples...')\n",
    "                save_samples(samples[epoch+1], epoch+1, output_dir)\n",
    "\n",
    "    ## Get final discriminator loss\n",
    "    # Get noise\n",
    "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda()\n",
    "    noise_v = autograd.Variable(noise,\n",
    "                                volatile=True)  # totally freeze model_gen\n",
    "\n",
    "    # Get new batch of real training data\n",
    "    D_cost_test, D_wass_test = compute_discr_loss_terms(\n",
    "        model_dis, model_gen, test_data_v, noise_v, batch_size, latent_dim,\n",
    "        lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "    D_cost_valid, D_wass_valid = compute_discr_loss_terms(\n",
    "        model_dis, model_gen, valid_data_v, noise_v, batch_size, latent_dim,\n",
    "        lmbda, use_cuda, compute_grads=False)\n",
    "\n",
    "    if use_cuda:\n",
    "        D_cost_test = D_cost_test.cpu()\n",
    "        D_cost_valid = D_cost_valid.cpu()\n",
    "        D_wass_test = D_wass_test.cpu()\n",
    "        D_wass_valid = D_wass_valid.cpu()\n",
    "\n",
    "    final_discr_metrics = {\n",
    "        'cost_validation': D_cost_valid.data.numpy()[0],\n",
    "        'wasserstein_cost_validation': D_wass_valid.data.numpy()[0],\n",
    "        'cost_test': D_cost_test.data.numpy()[0],\n",
    "        'wasserstein_cost_test': D_wass_test.data.numpy()[0],\n",
    "    }\n",
    "\n",
    "    return model_gen, model_dis, history, final_discr_metrics, samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"../../wvgan_out\"\n",
    "model_dir = os.path.join(output_dir,\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    # Create output directory\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_size = 64\n",
    "phase_shuffle_shift_factor = 2 \n",
    "post_proc_filt_len = 512 \n",
    "lrelu_alpha = 0.2 \n",
    "valid_ratio = 0.1 \n",
    "test_ratio = 0.1 \n",
    "batch_size = 64 \n",
    "num_epochs = 100 \n",
    "batches_per_epoch = 10 \n",
    "ngpus = 1 \n",
    "discriminator_updates = 5 \n",
    "latent_dim = 100 \n",
    "epochs_per_sample = 1 \n",
    "sample_size = 20 \n",
    "learning_rate = 0.0001 \n",
    "beta_one = 0.5 \n",
    "beta_two = 0.9\n",
    "regularization_factor = 10.0 \n",
    "batch_shuffle = False\n",
    "\n",
    "audio_dir = \"/home/nl1115/gc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try on some training data\n",
    "print('Loading audio data...')\n",
    "audio_filepaths = get_all_audio_filepaths(audio_dir)\n",
    "train_gen, valid_data, test_data \\\n",
    "    = create_data_split(audio_filepaths, valid_ratio, test_ratio,\n",
    "                        batch_size, batch_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating models...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Creating models...')\n",
    "model_gen = WaveGANGenerator(model_size=model_size, ngpus=ngpus, latent_dim=latent_dim,\n",
    "                             post_proc_filt_len=post_proc_filt_len,upsample=True)\n",
    "model_dis = WaveGANDiscriminator(model_size=model_size, ngpus=ngpus,\n",
    "                                 alpha=lrelu_alpha, shift_factor=phase_shuffle_shift_factor,\n",
    "                                 batch_shuffle=batch_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveGANGenerator(\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (upSampConv1): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=nearest)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(1024, 512, kernel_size=(25,), stride=(4,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv2): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=nearest)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(512, 256, kernel_size=(25,), stride=(4,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv3): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=nearest)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(256, 128, kernel_size=(25,), stride=(4,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv4): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=nearest)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(128, 64, kernel_size=(25,), stride=(4,))\n",
      "    )\n",
      "  )\n",
      "  (upSampConv5): DataParallel(\n",
      "    (module): UpsampleConvLayer(\n",
      "      (upsample_layer): Upsample(scale_factor=4, mode=nearest)\n",
      "      (reflection_pad): ReflectionPad1d((12, 12))\n",
      "      (conv1d): Conv1d(64, 1, kernel_size=(25,), stride=(4,))\n",
      "    )\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "result of slicing is an empty tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cfdc1871489e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepochs_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_per_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     sample_size=sample_size)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished training.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-787689d8e773>\u001b[0m in \u001b[0;36mtrain_wgan\u001b[0;34m(model_gen, model_dis, train_gen, valid_data, test_data, num_epochs, batches_per_epoch, batch_size, output_dir, lmbda, use_cuda, discriminator_updates, epochs_per_sample, sample_size, lr, beta_1, beta_2, latent_dim)\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mmodel_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     lmbda, use_cuda, compute_grads=True)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# Update the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e8e198c44042>\u001b[0m in \u001b[0;36mcompute_discr_loss_terms\u001b[0;34m(model_dis, model_gen, real_data_v, noise_v, batch_size, latent_dim, lmbda, use_cuda, compute_grads)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0minputv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/beegfs/nl1115/miniconda3/envs/aml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a1bf0ec84ee6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/beegfs/nl1115/miniconda3/envs/aml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9fcf2c302289>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mx_shuffle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mx_shuffle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/beegfs/nl1115/miniconda3/envs/aml/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/beegfs/nl1115/miniconda3/envs/aml/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: result of slicing is an empty tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Starting training...')\n",
    "model_gen, model_dis, history, final_discr_metrics, samples = train_wgan(\n",
    "    model_gen=model_gen,\n",
    "    model_dis=model_dis,\n",
    "    train_gen=train_gen,\n",
    "    valid_data=valid_data,\n",
    "    test_data=test_data,\n",
    "    num_epochs=num_epochs,\n",
    "    batches_per_epoch=batches_per_epoch,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=model_dir,\n",
    "    lr=learning_rate,\n",
    "    beta_1=beta_one,\n",
    "    beta_2=beta_two,\n",
    "    use_cuda=ngpus>=1,\n",
    "    discriminator_updates=discriminator_updates,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs_per_sample=epochs_per_sample,\n",
    "    sample_size=sample_size)\n",
    "\n",
    "print('Finished training.')\n",
    "\n",
    "print('Final discriminator loss on validation and test:')\n",
    "print(pprint.pformat(final_discr_metrics))\n",
    "\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
